<!DOCTYPE html>
<html lang="en">

<body>


<!-- Rules Modal -->
<div>
    <div >
        <h2>Developed with TU Delft values of Integrity, Respect, and Responsibility</h2>
        <p>This tool helps you pre-screen audio and video so freely available speech data can be used to train inclusive
            models without importing extremist content or bias.
            Our system analyzes spoken content and classifies it into three categories:
        </p>
        <ul>
            <li>Offensive Language</li>
            <li>Extremist View</li>
            <li>Appropriate Speech</li>
        </ul>
        <h3>How We Define These Categories</h3>
        <ul>
            <li><b>Offensive Language:</b></li>
            <p>Speech containing words or expressions widely recognized as offensive or inappropriate, such as
                profanity, slurs, or explicit insults.
                <br><br>
                <i>→ Keyword-based:</i> the system detects specific terms generally considered offensive in most
                usages and labels them directly as hate speech independent of the context.
            <li> <b>Extremist Views:</b></li>
            <p>Statements that express extreme beliefs and/or strict opinions on societally significant topics
                regardless of where they lie on the ethical, socioeconomic and political spectrum are considered
                extremist views. If they promote intolerance, violence, or discrimination against others, they are
                directly marked.
                <br><br><i>→ Context matters most: </i>the system analyzes the meaning of the entire statement, not just
                individual
                words.
            <li><b>Appropriate Speech:</b></li>
            <p>Content that does not include hate speech or extremist views.
            </p>
        </ul>
    </div>
</div>






</div>
</body>
</html>
